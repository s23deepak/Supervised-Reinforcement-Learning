# Logical Reasoning Training Configuration for Synthetic Data Kit

# Global paths configuration
paths:
  input: "data/input"           # Source PDFs and text files
  output:
    parsed: "data/parsed"       # Extracted text files (.txt)
    generated: "data/generated" # Generated QA pairs and CoT (.json)
    curated: "data/curated"     # Quality-filtered data (.json)
    final: "data/final"         # Training-ready format (.json)

# LLM Provider configuration
llm:
  provider: "vllm"

# vLLM server configuration
vllm:
  api_base: "http://localhost:8001/v1"
  port: 8001
  model: "Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4"
  max_retries: 3
  retry_delay: 1.0
  sleep_time: 0.1   # Small delay between batches to avoid rate limits

# Document processing configuration
ingest:
  default_format: "txt"
  youtube_captions: "auto"

# LLM generation parameters optimized for logical reasoning
generation:
  temperature: 0.7   # Balanced creativity for reasoning problems
  top_p: 0.95

  # Document processing strategy
  processing_strategy: "auto"
  single_call_max_size: 8000

  # Chunking parameters for large documents
  chunk_size: 4000   # Good size for logical reasoning content
  overlap: 300       # Maintain context between chunks

  # Content generation targets
  num_pairs: 15      # QA pairs per document/chunk
  num_cot_examples: 10  # Chain of Thought examples per document/chunk

  # Model parameters
  max_tokens: 4096   # Allow detailed reasoning
  batch_size: 16     # Reasonable batch size for reasoning tasks

  # Quality settings
  enable_deduplication: true
  similarity_threshold: 0.85  # Remove very similar problems

# Content curation parameters - stricter for reasoning quality
curate:
  threshold: 7.5     # Higher threshold for logical reasoning quality
  batch_size: 5      # Smaller batches for more careful evaluation
  inference_batch: 5
  temperature: 0.1   # Low temperature for consistent quality ratings

# Format conversion parameters
format:
  default: "alpaca"  # Use Alpaca format for fine-tuning
  include_metadata: true
  pretty_json: true

# Specialized prompts for logical reasoning domains
prompts:
  # Summary generation for logical reasoning content
  summary: |
    Summarize this logical reasoning content in 3-5 sentences, focusing on:
    1. The type of logical problems covered (Seating Arrangements or Blood Relations)
    2. Key solving strategies mentioned
    3. Important concepts and principles for these specific domains

  # QA pair generation optimized for logical reasoning
  qa_generation: |
    Create {num_pairs} high-quality logical reasoning question-answer pairs from this educational content.

    Focus on problems that require:
    1. Step-by-step logical deduction
    2. Testing assumptions and eliminating contradictions
    3. Clear reasoning
    4. Progressive difficulty (basic → intermediate → advanced)

    Domain Guidelines:
    - Seating Arrangements: Focus on constraint satisfaction, systematic placement
    - Blood Relations: Focus on family tree deduction, relationship mapping

    IMPORTANT: Don't include any numeric style seating arrangements questions,
    e.g., how many permutations such arrangements possible, etc.
    Focus on "who sits where" or "who is related to whom" type questions only.

    Return ONLY valid JSON in this exact format with multiple-choice questions:
    [
      {{
        "question": "Clear, specific logical reasoning question requiring step-by-step thinking with context?",
        "choices": [
          "A) First option",
          "B) Second option",
          "C) Third option",
          "D) Fourth option"
        ],
        "answer": "B",
        "reasoning": "Complete step-by-step solution showing the reasoning process, testing assumptions, and reaching the final answer. Explain why the chosen answer is correct and how to eliminate other options."
      }},
      {{
        "question": "Another logical reasoning question with different complexity?",
        "choices": [
          "A) First option",
          "B) Second option",
          "C) Third option",
          "D) Fourth option"
        ],
        "answer": "C",
        "reasoning": "Detailed answer showing each deduction step, how contradictions are resolved, and verification of the solution. Break down the logic clearly."
      }}
    ]

    Text:
    {text}

  # Chain of Thought generation for complex logical reasoning
  cot_generation: |
    Create  complex logical reasoning problems with detailed chain-of-thought solutions from this content.

    Focus on these domains only:
    - Seating Arrangements: Linear, circular, parallel rows, facing directions
    - Blood Relations: Family trees, relationship mapping, generational logic

    IMPORTANT: Don't include any numeric style seating arrangements questions,
    e.g., how many permutations such arrangements possible, etc.
    Focus on "who sits where" or "who is related to whom" type questions only.

    Each problem should:
    1. Require multiple reasoning steps and careful analysis
    2. Show how to test different possibilities systematically
    3. Demonstrate how to identify and resolve contradictions
    4. Include verification that the solution satisfies all constraints
    5. Explain the reasoning behind each step

    Chain-of-Thought Structure:
    - Identify what is known and what needs to be found
    - Break down the problem into manageable steps
    - Test different cases or assumptions
    - Show how contradictions eliminate invalid options
    - Verify the final answer against all given conditions

    Return ONLY valid JSON in this exact format with multiple-choice questions:
    [
      {{
        "question": "Complex multi-step logical reasoning problem that requires systematic analysis?",
        "choices": [
          "A) First option",
          "B) Second option",
          "C) Third option",
          "D) Fourth option"
        ],
        "answer": "A",
        "reasoning": "Step 1: First, let me identify what we know from the problem statement...\\nStep 2: Now I need to consider the possible cases. If we assume X is true, then...\\nStep 3: This assumption leads to a contradiction because...\\nStep 4: So X must be false. Let me try the opposite assumption...\\nStep 5: Testing this new assumption: if Y is true, then...\\nStep 6: This works! Let me verify by checking all constraints...\\nStep 7: Checking constraint 1: ✓... Checking constraint 2: ✓...\\n\\nFinal answer: The solution is [answer] because [key insight that makes this the only valid solution]."
      }}
    ]

    Text:
    {text}

  # Quality rating prompt for logical reasoning content
  qa_rating: |
    Rate each logical reasoning question-answer pair on a scale from 1-10 based on:

    DOMAIN RELEVANCE (0-1 point):
    - Does it focus on Seating Arrangements or Blood Relations?
    - Deduct points if it strays from these two domains

    ACCURACY (0-3 points):
    - Is the logic sound and free from errors?
    - Are all reasoning steps valid?
    - Is the final answer correct?
    - Do all multiple-choice options make sense?

    CLARITY (0-2 points):
    - Is the question clearly stated?
    - Is the reasoning easy to follow?
    - Are the choices distinct and unambiguous?

    REASONING QUALITY (0-3 points):
    - Does it show step-by-step logical deduction?
    - Are assumptions tested properly?
    - Are contradictions identified and resolved?
    - Does the reasoning justify why the correct answer is right?

    EDUCATIONAL VALUE (0-1 point):
    - Does it teach logical reasoning skills?
    - Is the difficulty level appropriate?

    YOU MUST RETURN VALID JSON WITH THIS EXACT SCHEMA:
    {{
      "question": "Exact question text",
      "choices": ["A) ...", "B) ...", "C) ...", "D) ..."],
      "answer": "B",
      "reasoning": "Exact reasoning text",
      "rating": 8
    }}

    OR FOR MULTIPLE PAIRS:
    [
      {{"question": "Q1", "choices": ["A) ...", "B) ...", "C) ...", "D) ..."], "answer": "A", "reasoning": "E1", "rating": 8}},
      {{"question": "Q2", "choices": ["A) ...", "B) ...", "C) ...", "D) ..."], "answer": "C", "reasoning": "E2", "rating": 9}}
    ]

    *** RETURN ONLY JSON - NO EXPLANATION OR MARKDOWN ***

    QA pairs to rate:
    {pairs}
